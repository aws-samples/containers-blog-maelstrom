{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview \u00b6 Welcome to the Amazon Containers Blog Maelstrom documentation site. This repository accompaniment to blog posts published on the AWS Containers Blog . It can be used by AWS customers, partners, and internal AWS teams to configure and manage complete EKS clusters that are fully bootstrapped with the operational software that is needed to deploy and operate workloads.","title":"Overview"},{"location":"#overview","text":"Welcome to the Amazon Containers Blog Maelstrom documentation site. This repository accompaniment to blog posts published on the AWS Containers Blog . It can be used by AWS customers, partners, and internal AWS teams to configure and manage complete EKS clusters that are fully bootstrapped with the operational software that is needed to deploy and operate workloads.","title":"Overview"},{"location":"aws-cdk-eks-multi-region-skeleton/","text":"Manage your EKS Cluster with CDK \u00b6 This repository holds the skeleton code where you would start the journey to Manage your EKS Cluster with CDK Hands-on Lab. Please clone this repository and start the workshop to play with the lab. :) Related Repository \u00b6 Skeleton Repository : You would clone this repository and build up the code as going through the steps in the lab. Full-code Repository : Once you complete the workshop, the code would look like this repository! You can also use this repository as a sample code to actually build CDK project for your own infrastructure and containers. CI/CD for CDK : Fabulous CDK team is working on providing CI/CD natively, in the meantime, you can check out simple way to do it with AWS CodePipeline and CodeBuild. Sample App for Multi-region Application Deployment : In third lab of this workshop , you will deploy your application in your developer's shoes. This repository holds the sample app to deploy. The sample simply says 'Hello World' with the information where it is hosted.","title":"Multi Region EKS Clusters with CDK"},{"location":"aws-cdk-eks-multi-region-skeleton/#manage-your-eks-cluster-with-cdk","text":"This repository holds the skeleton code where you would start the journey to Manage your EKS Cluster with CDK Hands-on Lab. Please clone this repository and start the workshop to play with the lab. :)","title":"Manage your EKS Cluster with CDK"},{"location":"aws-cdk-eks-multi-region-skeleton/#related-repository","text":"Skeleton Repository : You would clone this repository and build up the code as going through the steps in the lab. Full-code Repository : Once you complete the workshop, the code would look like this repository! You can also use this repository as a sample code to actually build CDK project for your own infrastructure and containers. CI/CD for CDK : Fabulous CDK team is working on providing CI/CD natively, in the meantime, you can check out simple way to do it with AWS CodePipeline and CodeBuild. Sample App for Multi-region Application Deployment : In third lab of this workshop , you will deploy your application in your developer's shoes. This repository holds the sample app to deploy. The sample simply says 'Hello World' with the information where it is hosted.","title":"Related Repository"},{"location":"batch-processing-with-k8s/","text":"Batch processing in scale using K8s jobs and step functions \u00b6 This article talks about an approach that can help customers scale large file processing workloads in AWS EKS using Kubernetes jobs and AWS step functions. Introduction \u00b6 This approach uses AWS step functions to orchestrate the end to end flow, which involves: Reading of the input file from AWS S3 Splitting the large input file into smaller files, processing it, saving the data into a database Writing the output file to AWS S3 Before we get into the implementation details, let us discuss the alternative approach to address the same use case. Sequential read (aka single-threaded) - This approach uses a simple file reader that reads the large file row by row and processes it. Big data system (using spark) - This approach is quite popular and commonly implemented when it comes to processing large files. It uses spark api's like spark.csv.read() to read the file, convert them into dataframes or RDD, process them and write the data back into to a data lake as CSV, txt or parquet files Stream-based system (using message bus) - In this approach, a program reads the file row by row and pushes the records as individual messages to a message bus (like Kafka or AWS Kinesis streams ). A consumer (like AWS Lambda) reads the message, processes it, and stores the result in a file system or database Note: Let us assume a large file, in this case, refers to a file with at least one million records, delimited by line breaks (with each row presenting a single record) Here is a relative comparison of these approaches: Name Description Sequential read (#1) Big data system (#2) Stream-based system (#3) Row order Can the output file be generated in the same row order as input file Yes No No Horizontal scaling Will horizontal scaling help? No Yes Yes Vertical scaling Will vertical scaling help? Yes Yes Yes Processing time Time taken to process a large file Relatively slow Faster than option #1 Faster than option #1 Level of refactor Percentage of refactoring required in moving an existing codebase 30% to 40% 80% to 90% 60% to 70% Each of these approaches has its advantages (like scaling, elasticity) and disadvantages (like maintaining row order, level of refactoring involved) when comparing with one another. So part of this article, let us see how we can implement an hybrid approach that can provide scalability, elasticity, and still maintain the row order in the output file with an acceptable (30% to 40%) level of refactoring. Solution overview \u00b6 AWS Services \u00b6 AWS Step function and Kubernetes Job are the two essential technologies used to implement this approach, and here is a high level overview of them. AWS Step function \u00b6 AWS Step Functions is a serverless function orchestrator that makes it easy to sequence AWS Lambda functions and multiple AWS services into business-critical applications. Through its visual interface, you can create and run a series of checkpointed and event-driven workflows that maintain the application state. Read more about it here Kubernetes Job \u00b6 A Job creates one or more Pods and will continue to retry execution of the Pods until a specified number of them successfully terminate. As pods complete, the job tracks the successful completions. When a specified number of successful completions is reached, the task (ie, job) is done. Read more about it here Sample application \u00b6 To demonstrate this approach, we have implemented a sample application that can take in an input file, process it, save the data in Dynamodb and write the output file to AWS S3 . The below image shows the high-level architecture of the application: Here is the end to end flow of the application: AWS Step function is invoked when the input file gets dropped into the AWS S3 bucket. AWS Cloudtrail listens to all the write events of the input S3 bucket. AWS Step functions will execute the below steps, part of file processing: File splitter - Kubernetes job will read the input file from S3. File splitter will split the large input file into smaller files and writes them to the Elastic file system mounted on the pod. The program uses the Unix split command to chunk the large files into smaller ones, with each file containing a maximum of MAX_LINES_PER_BATCH lines, set in the environment variable, defaults to 30000. Save the path of the split files in AWS Elastic cache (Redis) that will get used in tracking the overall progress of this job. The data in Redis cache gets stored in this format: | Format | Data type | Sample data | | ----- | ------------- | ----- | | | <string, set\\<string>> | <CloudTrail_Event_Id, Set\\<\\<EFS_Path_Of_SplitFiles>> | Split-file-lambda - Lambda function will read the Redis cache and return an array of split file locations as response Map state will use the split files array as input and create parallel Kubernetes jobs to process all these split files in parallel, with an MaxConcurrency = 0 . Each job will receive one split file as input and takes care of the following: Read the split file from the EFS location Process each row, generate ConfirmationId for OrderId field available in the input. Save the information in AWS Dynamodb under Orders table. All dynamodb writes are batched to a maximum of 25 rows per request. Part of this process, a CSV file gets created in EFS location with each row containing both ConfirmationId and OrderId , written in batch Updates elastic cache by removing split file (path) from Redis set using rdb.SRem command If the set associated with the CloudTrail_Event_Id is empty, then all the parallel file processing jobs are complete. So we can merge the output split files in the EFS directory and upload them to the S3 bucket Note: It\u2019s very important to settle on a right value for the maximum number of rows a split input file can contain. We set this value via MAX_LINES_PER_BATCH environment variable. Giving a smaller value will end up with too many split files causing too many containers to get created, and setting a large value will leaves too little scope for parallelism. Below are the snapshots of various artifacts used in this flow Input file: Region Country Item Type Sales Channel Order Priority Order Date Order ID Ship Date Units Sold Unit Price Unit Cost Total Revenue Total Cost Total Profit Sub-Saharan Africa South Africa Fruits Offline M 7/27/2012 791862618 7/28/2012 1593 9.33 6.92 14862.69 11023.56 3839.13 Output file: 791862618,aefa3585-7f46-476e-bc22-70181704c240 Orders (Dynamodb table): Region Country Item Type Sales Channel Order Priority Order Date Order ID Ship Date Units Sold Unit Price Unit Cost Total Revenue Total Cost Total Profit ConfirmationId Sub-Saharan Africa South Africa Fruits Offline M 7/27/2012 791862618 7/28/2012 1593 9.33 6.92 14862.69 11023.56 3839.13 aefa3585-7f46-476e-bc22-70181704c240 Build and Deployment \u00b6 Pre-requistes \u00b6 AWS CDK should be installed in the local laptop. You can read more about it here Yarn needs to be installed, you can check the installation status by running this command An AWS account with console and API access Docker desktop needs to be installed in the local laptop, you can read more about it here yarn version Output 1.22.10 If Yarn is not installed, run the following command npm install -g yarn Build \u00b6 Check out the code from this repository using this command: mkdir batch-processing-with-k8s && cd batch-processing-with-k8s git clone git@ssh.gitlab.aws.dev:am3-app-modernization-gsp/eks/batch-processing-with-k8s.git . Note: Source code for all Kubernetes jobs and lambda functions are available under src folder Deploy \u00b6 Code for the sample application using this CDK construct is available in src/integ.default.ts . In order to deploy the application, first bootstrap a CDK environment (if you haven't done so already). # Bootstrap CDK (ONLY ONCE, if you have already done this you can skip this part) # Subsitute your AWS Account Id and AWS region in the command below cdk bootstrap \\ --cloudformation-execution-policies arn:aws:iam::aws:policy/AdministratorAccess \\ aws://<AWS Account Id>/<AWS_REGION> The code is created as a CDK construct, the following parameters can be customized as part of the deployment Parameter Description Default vpc VPC in which the resources needs to be created New VPC will be created minNodes Autoscaling parameter for minimum value for EKS worker nodes 5 desiredNodes Autoscaling parameter for desired value for EKS worker nodes 5 maxNodes Autoscaling parameter for maximum value for EKS worker nodes 5 inputBucket S3 bucket, where the input files will get dropped input-bucket maxSplitLines Maximum number of records per split input file 30000 Run the following command to start the deployment cdk deploy --require-approval never Once the deployment is successful, you will see the following output: \u2705 file-batch-stack Outputs: file-batch-stack.KubernetesFileBatchConstructInputBucketName610D8598 = file-batch-stack-kubernetesfilebatchconstructinpu-1u3xbu9ycgorp file-batch-stack.KubernetesFileBatchConstructMultithreadedstepfuctionF3358A99 = KubernetesFileBatchConstructfilebatchmultithreaded0B80AF5A-abBRhxEtxLig file-batch-stack.KubernetesFileBatchConstructfilebatchEFSFileSystemId9139F216 = fs-696fb5dd file-batch-stack.KubernetesFileBatchConstructfilebatcheksclusterClusterName146E1BCB = KubernetesFileBatchConstructfilebatchekscluster6B334C7D-7874a48b84604e20a0dc68ecd3715e27 file-batch-stack.KubernetesFileBatchConstructfilebatcheksclusterConfigCommand3063A155 = aws eks update-kubeconfig --name KubernetesFileBatchConstructfilebatchekscluster6B334C7D-7874a48b84604e20a0dc68ecd3715e27 --region us-east-1 --role-arn arn:aws:iam::775492342640:role/file-batch-stack-KubernetesFileBatchConstructfileb-146I0AN7L7JXW file-batch-stack.KubernetesFileBatchConstructfilebatcheksclusterGetTokenCommandAD6928E0 = aws eks get-token --cluster-name KubernetesFileBatchConstructfilebatchekscluster6B334C7D-7874a48b84604e20a0dc68ecd3715e27 --region us-east-1 --role-arn arn:aws:iam::775492342640:role/file-batch-stack-KubernetesFileBatchConstructfileb-146I0AN7L7JXW file-batch-stack.KubernetesFileBatchConstructfilebatcheksclusterMastersRoleArn52BC348E = arn:aws:iam::775492342640:role/file-batch-stack-KubernetesFileBatchConstructfileb-146I0AN7L7JXW Stack ARN: arn:aws:cloudformation:us-east-1:775492342640:stack/file-batch-stack/886208f0-aeb2-11eb-9592-0e4dccb471bf Note: Make sure to run the ClusterConfig command available part of the CDK output. CDK script will add the newly created AWS EKS cluster to the kubeconfig to run kubectl command using this. The deployment will take care of building the docker images for all the k8s jobs, lambda functions and uploading it to AWS ECR Testing \u00b6 Unit testing \u00b6 Unit testcases can be executed by running the following command from the root directory yarn test yarn run v1.22.10 $ npx projen test \ud83e\udd16 test | rm -fr lib/ \ud83e\udd16 test \u00bb test:compile | tsc --noEmit --project tsconfig.jest.json \ud83e\udd16 test | jest --passWithNoTests --all --updateSnapshot PASS test/index.test.ts ( 7 .722 s ) \u2713 create app ( 3181 ms ) ---------- | --------- | ---------- | --------- | --------- | ------------------- File | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s ---------- | --------- | ---------- | --------- | --------- | ------------------- All files | 95 .95 | 75 | 85 .71 | 95 .95 | index.ts | 95 .95 | 75 | 85 .71 | 95 .95 | 558 -642 ---------- | --------- | ---------- | --------- | --------- | ------------------- Test Suites: 1 passed, 1 total Tests: 1 passed, 1 total Snapshots: 0 total Time: 8 .56 s Ran all test suites. \ud83e\udd16 test \u00bb eslint | eslint --ext .ts,.tsx --fix --no-error-on-unmatched-pattern src test build-tools .projenrc.js \u2728 Done in 24 .16s. Integration test \u00b6 Lets run a simple end to end integration test using a simple input file test.csv under payload folder. Run the following command from the root directory: > aws s3api put-object --bucket <<input_bucket>> --key test.csv --body payload/test.csv Note: Replace input_bucket with the actual input bucket available part of the CDK output Output { \"ETag\" : \"\\\"3ff3c83af2553279cd0f6f8fcf59980a\\\"\" } Now the step function should get automatically triggered and see the updates in the execution details page. Navigate to the state machine homepage and select the state machine created by the CDK (available part of the CDK output). The step function should successfully get executed, and it should look like below in the execution details page: The response file can be downloaded by running the following command: aws s3 cp s3://<<input_bucket>>/test.csv_Output . Note: Replace input_bucket with the actual input bucket available part of the CDK output Output download: s3:// <<input_bucket>>/test.csv_Sin gle_Output to ./test.csv_Single_Output Performance testing \u00b6 Let\u2019s run some performance tests with different datasets varying from 200 rows to 2 million rows and see how the system behaves in scaling up and processing these files quicker. To represent the \"Sequential read (aka single-threaded)\" approach, we created a step function with just one step calling Kubernetes job, which takes care of reading the input file, processing it, saving the data in dynamodb, and uploading the output file to AWS S3. Code to create this step function is available part of the CDK index.ts . To create this step function uncomment lines from 187 to 193, comment everything from 178 to 184 and then run cdk deploy --require-approval never . This will delete the multi-threaded step function (enabled with map construct) and create the single-threaded one Results \u00b6 File Records Sequential read Parallel (map) test.csv 200 68 seconds 117 seconds data.csv 1 Million 545 seconds 189 seconds data2M.csv 2 Million 1194 seconds 243 seconds Once we plot the numbers in a chart, here is how it looks like: As the load grows, we can see the \"Parallel (map)\" approach scales better compared to the \"Sequential read\" model. Note: All the payloads used in running these tests are available part of the payload folder in the root directory Here is how varying the value of MAX_LINES_PER_BATCH environment variable can fluctuate the overall performance of the system. As highlighted above just setting the smallest value to MAX_LINES_PER_BATCH variable doesn't make the system to run automatically faster. As we have set MaxConcurrency to zero in the map state, AWS step function will try to provide maximum parallelism by running as many k8s jobs as possible in parallel. So all the k8s jobs will start competing for the same hardware resources (EKS worker nodes) which will make concurrency more a bottleneck rather than a value add. We can overcome this behavior by setting the right value to MaxConcurrency attribute and enabling autoscaling for EKS worker nodes. Scaling EKS worker are faster but they are not instantaneous so the whole scaling process by itself will definitely take sometime, eventually causing delays in the processing of workload. So its definitely essential to run some experiments and decide on right values for both MAX_LINES_PER_BATCH environment variable and MaxConcurrency attribute in Map state Cleanup \u00b6 Run the following command from the root directory to delete the stack cdk destroy Resources \u00b6 AWS Step functions Kubernetes jobs Amazon EKS with Step function CSI Driver EFS Unix split command Redis set commands","title":"Batch Processing with K8s"},{"location":"batch-processing-with-k8s/#batch-processing-in-scale-using-k8s-jobs-and-step-functions","text":"This article talks about an approach that can help customers scale large file processing workloads in AWS EKS using Kubernetes jobs and AWS step functions.","title":"Batch processing in scale using K8s jobs and step functions"},{"location":"batch-processing-with-k8s/#introduction","text":"This approach uses AWS step functions to orchestrate the end to end flow, which involves: Reading of the input file from AWS S3 Splitting the large input file into smaller files, processing it, saving the data into a database Writing the output file to AWS S3 Before we get into the implementation details, let us discuss the alternative approach to address the same use case. Sequential read (aka single-threaded) - This approach uses a simple file reader that reads the large file row by row and processes it. Big data system (using spark) - This approach is quite popular and commonly implemented when it comes to processing large files. It uses spark api's like spark.csv.read() to read the file, convert them into dataframes or RDD, process them and write the data back into to a data lake as CSV, txt or parquet files Stream-based system (using message bus) - In this approach, a program reads the file row by row and pushes the records as individual messages to a message bus (like Kafka or AWS Kinesis streams ). A consumer (like AWS Lambda) reads the message, processes it, and stores the result in a file system or database Note: Let us assume a large file, in this case, refers to a file with at least one million records, delimited by line breaks (with each row presenting a single record) Here is a relative comparison of these approaches: Name Description Sequential read (#1) Big data system (#2) Stream-based system (#3) Row order Can the output file be generated in the same row order as input file Yes No No Horizontal scaling Will horizontal scaling help? No Yes Yes Vertical scaling Will vertical scaling help? Yes Yes Yes Processing time Time taken to process a large file Relatively slow Faster than option #1 Faster than option #1 Level of refactor Percentage of refactoring required in moving an existing codebase 30% to 40% 80% to 90% 60% to 70% Each of these approaches has its advantages (like scaling, elasticity) and disadvantages (like maintaining row order, level of refactoring involved) when comparing with one another. So part of this article, let us see how we can implement an hybrid approach that can provide scalability, elasticity, and still maintain the row order in the output file with an acceptable (30% to 40%) level of refactoring.","title":"Introduction"},{"location":"batch-processing-with-k8s/#solution-overview","text":"","title":"Solution overview"},{"location":"batch-processing-with-k8s/#aws-services","text":"AWS Step function and Kubernetes Job are the two essential technologies used to implement this approach, and here is a high level overview of them.","title":"AWS Services"},{"location":"batch-processing-with-k8s/#aws-step-function","text":"AWS Step Functions is a serverless function orchestrator that makes it easy to sequence AWS Lambda functions and multiple AWS services into business-critical applications. Through its visual interface, you can create and run a series of checkpointed and event-driven workflows that maintain the application state. Read more about it here","title":"AWS Step function"},{"location":"batch-processing-with-k8s/#kubernetes-job","text":"A Job creates one or more Pods and will continue to retry execution of the Pods until a specified number of them successfully terminate. As pods complete, the job tracks the successful completions. When a specified number of successful completions is reached, the task (ie, job) is done. Read more about it here","title":"Kubernetes Job"},{"location":"batch-processing-with-k8s/#sample-application","text":"To demonstrate this approach, we have implemented a sample application that can take in an input file, process it, save the data in Dynamodb and write the output file to AWS S3 . The below image shows the high-level architecture of the application: Here is the end to end flow of the application: AWS Step function is invoked when the input file gets dropped into the AWS S3 bucket. AWS Cloudtrail listens to all the write events of the input S3 bucket. AWS Step functions will execute the below steps, part of file processing: File splitter - Kubernetes job will read the input file from S3. File splitter will split the large input file into smaller files and writes them to the Elastic file system mounted on the pod. The program uses the Unix split command to chunk the large files into smaller ones, with each file containing a maximum of MAX_LINES_PER_BATCH lines, set in the environment variable, defaults to 30000. Save the path of the split files in AWS Elastic cache (Redis) that will get used in tracking the overall progress of this job. The data in Redis cache gets stored in this format: | Format | Data type | Sample data | | ----- | ------------- | ----- | | | <string, set\\<string>> | <CloudTrail_Event_Id, Set\\<\\<EFS_Path_Of_SplitFiles>> | Split-file-lambda - Lambda function will read the Redis cache and return an array of split file locations as response Map state will use the split files array as input and create parallel Kubernetes jobs to process all these split files in parallel, with an MaxConcurrency = 0 . Each job will receive one split file as input and takes care of the following: Read the split file from the EFS location Process each row, generate ConfirmationId for OrderId field available in the input. Save the information in AWS Dynamodb under Orders table. All dynamodb writes are batched to a maximum of 25 rows per request. Part of this process, a CSV file gets created in EFS location with each row containing both ConfirmationId and OrderId , written in batch Updates elastic cache by removing split file (path) from Redis set using rdb.SRem command If the set associated with the CloudTrail_Event_Id is empty, then all the parallel file processing jobs are complete. So we can merge the output split files in the EFS directory and upload them to the S3 bucket Note: It\u2019s very important to settle on a right value for the maximum number of rows a split input file can contain. We set this value via MAX_LINES_PER_BATCH environment variable. Giving a smaller value will end up with too many split files causing too many containers to get created, and setting a large value will leaves too little scope for parallelism. Below are the snapshots of various artifacts used in this flow Input file: Region Country Item Type Sales Channel Order Priority Order Date Order ID Ship Date Units Sold Unit Price Unit Cost Total Revenue Total Cost Total Profit Sub-Saharan Africa South Africa Fruits Offline M 7/27/2012 791862618 7/28/2012 1593 9.33 6.92 14862.69 11023.56 3839.13 Output file: 791862618,aefa3585-7f46-476e-bc22-70181704c240 Orders (Dynamodb table): Region Country Item Type Sales Channel Order Priority Order Date Order ID Ship Date Units Sold Unit Price Unit Cost Total Revenue Total Cost Total Profit ConfirmationId Sub-Saharan Africa South Africa Fruits Offline M 7/27/2012 791862618 7/28/2012 1593 9.33 6.92 14862.69 11023.56 3839.13 aefa3585-7f46-476e-bc22-70181704c240","title":"Sample application"},{"location":"batch-processing-with-k8s/#build-and-deployment","text":"","title":"Build and Deployment"},{"location":"batch-processing-with-k8s/#pre-requistes","text":"AWS CDK should be installed in the local laptop. You can read more about it here Yarn needs to be installed, you can check the installation status by running this command An AWS account with console and API access Docker desktop needs to be installed in the local laptop, you can read more about it here yarn version Output 1.22.10 If Yarn is not installed, run the following command npm install -g yarn","title":"Pre-requistes"},{"location":"batch-processing-with-k8s/#build","text":"Check out the code from this repository using this command: mkdir batch-processing-with-k8s && cd batch-processing-with-k8s git clone git@ssh.gitlab.aws.dev:am3-app-modernization-gsp/eks/batch-processing-with-k8s.git . Note: Source code for all Kubernetes jobs and lambda functions are available under src folder","title":"Build"},{"location":"batch-processing-with-k8s/#deploy","text":"Code for the sample application using this CDK construct is available in src/integ.default.ts . In order to deploy the application, first bootstrap a CDK environment (if you haven't done so already). # Bootstrap CDK (ONLY ONCE, if you have already done this you can skip this part) # Subsitute your AWS Account Id and AWS region in the command below cdk bootstrap \\ --cloudformation-execution-policies arn:aws:iam::aws:policy/AdministratorAccess \\ aws://<AWS Account Id>/<AWS_REGION> The code is created as a CDK construct, the following parameters can be customized as part of the deployment Parameter Description Default vpc VPC in which the resources needs to be created New VPC will be created minNodes Autoscaling parameter for minimum value for EKS worker nodes 5 desiredNodes Autoscaling parameter for desired value for EKS worker nodes 5 maxNodes Autoscaling parameter for maximum value for EKS worker nodes 5 inputBucket S3 bucket, where the input files will get dropped input-bucket maxSplitLines Maximum number of records per split input file 30000 Run the following command to start the deployment cdk deploy --require-approval never Once the deployment is successful, you will see the following output: \u2705 file-batch-stack Outputs: file-batch-stack.KubernetesFileBatchConstructInputBucketName610D8598 = file-batch-stack-kubernetesfilebatchconstructinpu-1u3xbu9ycgorp file-batch-stack.KubernetesFileBatchConstructMultithreadedstepfuctionF3358A99 = KubernetesFileBatchConstructfilebatchmultithreaded0B80AF5A-abBRhxEtxLig file-batch-stack.KubernetesFileBatchConstructfilebatchEFSFileSystemId9139F216 = fs-696fb5dd file-batch-stack.KubernetesFileBatchConstructfilebatcheksclusterClusterName146E1BCB = KubernetesFileBatchConstructfilebatchekscluster6B334C7D-7874a48b84604e20a0dc68ecd3715e27 file-batch-stack.KubernetesFileBatchConstructfilebatcheksclusterConfigCommand3063A155 = aws eks update-kubeconfig --name KubernetesFileBatchConstructfilebatchekscluster6B334C7D-7874a48b84604e20a0dc68ecd3715e27 --region us-east-1 --role-arn arn:aws:iam::775492342640:role/file-batch-stack-KubernetesFileBatchConstructfileb-146I0AN7L7JXW file-batch-stack.KubernetesFileBatchConstructfilebatcheksclusterGetTokenCommandAD6928E0 = aws eks get-token --cluster-name KubernetesFileBatchConstructfilebatchekscluster6B334C7D-7874a48b84604e20a0dc68ecd3715e27 --region us-east-1 --role-arn arn:aws:iam::775492342640:role/file-batch-stack-KubernetesFileBatchConstructfileb-146I0AN7L7JXW file-batch-stack.KubernetesFileBatchConstructfilebatcheksclusterMastersRoleArn52BC348E = arn:aws:iam::775492342640:role/file-batch-stack-KubernetesFileBatchConstructfileb-146I0AN7L7JXW Stack ARN: arn:aws:cloudformation:us-east-1:775492342640:stack/file-batch-stack/886208f0-aeb2-11eb-9592-0e4dccb471bf Note: Make sure to run the ClusterConfig command available part of the CDK output. CDK script will add the newly created AWS EKS cluster to the kubeconfig to run kubectl command using this. The deployment will take care of building the docker images for all the k8s jobs, lambda functions and uploading it to AWS ECR","title":"Deploy"},{"location":"batch-processing-with-k8s/#testing","text":"","title":"Testing"},{"location":"batch-processing-with-k8s/#unit-testing","text":"Unit testcases can be executed by running the following command from the root directory yarn test yarn run v1.22.10 $ npx projen test \ud83e\udd16 test | rm -fr lib/ \ud83e\udd16 test \u00bb test:compile | tsc --noEmit --project tsconfig.jest.json \ud83e\udd16 test | jest --passWithNoTests --all --updateSnapshot PASS test/index.test.ts ( 7 .722 s ) \u2713 create app ( 3181 ms ) ---------- | --------- | ---------- | --------- | --------- | ------------------- File | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s ---------- | --------- | ---------- | --------- | --------- | ------------------- All files | 95 .95 | 75 | 85 .71 | 95 .95 | index.ts | 95 .95 | 75 | 85 .71 | 95 .95 | 558 -642 ---------- | --------- | ---------- | --------- | --------- | ------------------- Test Suites: 1 passed, 1 total Tests: 1 passed, 1 total Snapshots: 0 total Time: 8 .56 s Ran all test suites. \ud83e\udd16 test \u00bb eslint | eslint --ext .ts,.tsx --fix --no-error-on-unmatched-pattern src test build-tools .projenrc.js \u2728 Done in 24 .16s.","title":"Unit testing"},{"location":"batch-processing-with-k8s/#integration-test","text":"Lets run a simple end to end integration test using a simple input file test.csv under payload folder. Run the following command from the root directory: > aws s3api put-object --bucket <<input_bucket>> --key test.csv --body payload/test.csv Note: Replace input_bucket with the actual input bucket available part of the CDK output Output { \"ETag\" : \"\\\"3ff3c83af2553279cd0f6f8fcf59980a\\\"\" } Now the step function should get automatically triggered and see the updates in the execution details page. Navigate to the state machine homepage and select the state machine created by the CDK (available part of the CDK output). The step function should successfully get executed, and it should look like below in the execution details page: The response file can be downloaded by running the following command: aws s3 cp s3://<<input_bucket>>/test.csv_Output . Note: Replace input_bucket with the actual input bucket available part of the CDK output Output download: s3:// <<input_bucket>>/test.csv_Sin gle_Output to ./test.csv_Single_Output","title":"Integration test"},{"location":"batch-processing-with-k8s/#performance-testing","text":"Let\u2019s run some performance tests with different datasets varying from 200 rows to 2 million rows and see how the system behaves in scaling up and processing these files quicker. To represent the \"Sequential read (aka single-threaded)\" approach, we created a step function with just one step calling Kubernetes job, which takes care of reading the input file, processing it, saving the data in dynamodb, and uploading the output file to AWS S3. Code to create this step function is available part of the CDK index.ts . To create this step function uncomment lines from 187 to 193, comment everything from 178 to 184 and then run cdk deploy --require-approval never . This will delete the multi-threaded step function (enabled with map construct) and create the single-threaded one","title":"Performance testing"},{"location":"batch-processing-with-k8s/#results","text":"File Records Sequential read Parallel (map) test.csv 200 68 seconds 117 seconds data.csv 1 Million 545 seconds 189 seconds data2M.csv 2 Million 1194 seconds 243 seconds Once we plot the numbers in a chart, here is how it looks like: As the load grows, we can see the \"Parallel (map)\" approach scales better compared to the \"Sequential read\" model. Note: All the payloads used in running these tests are available part of the payload folder in the root directory Here is how varying the value of MAX_LINES_PER_BATCH environment variable can fluctuate the overall performance of the system. As highlighted above just setting the smallest value to MAX_LINES_PER_BATCH variable doesn't make the system to run automatically faster. As we have set MaxConcurrency to zero in the map state, AWS step function will try to provide maximum parallelism by running as many k8s jobs as possible in parallel. So all the k8s jobs will start competing for the same hardware resources (EKS worker nodes) which will make concurrency more a bottleneck rather than a value add. We can overcome this behavior by setting the right value to MaxConcurrency attribute and enabling autoscaling for EKS worker nodes. Scaling EKS worker are faster but they are not instantaneous so the whole scaling process by itself will definitely take sometime, eventually causing delays in the processing of workload. So its definitely essential to run some experiments and decide on right values for both MAX_LINES_PER_BATCH environment variable and MaxConcurrency attribute in Map state","title":"Results"},{"location":"batch-processing-with-k8s/#cleanup","text":"Run the following command from the root directory to delete the stack cdk destroy","title":"Cleanup"},{"location":"batch-processing-with-k8s/#resources","text":"AWS Step functions Kubernetes jobs Amazon EKS with Step function CSI Driver EFS Unix split command Redis set commands","title":"Resources"},{"location":"prefetch-data-to-eks-nodes/","text":"This code is to validate benefits of Event Driven process to prefetch data to EKS Nodes using SSM Automation Solution Walkthrough Prerequisites To run this solution, you must have the following prerequisites: AWS CLI version 2.10 or higher (https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html) to interact with AWS services eksctl (https://eksctl.io/) for creating and managing your Amazon EKS cluster kubectl (https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html) for running kubectl commands on your Amazon EKS cluster envsubst (https://pkg.go.dev/github.com/a8m/envsubst#section-readme) for environment variables substitution for Go. jq (https://stedolan.github.io/jq/download/) for command-line JSON processing The source code for this blog is available in AWS-Samples on GitHub (https://github.com/aws-samples/containers-blog-maelstrom/tree/main/aws-eks-edp). Let\u2019s start by setting a few environment variables: export EDP_AWS_REGION=us-east-1 export EDP_AWS_ACCOUNT=$(aws sts get-caller-identity --query 'Account' --output text) export EDP_NAME=prefetching-data-automation Next, lets create Amazon Elastic Container Registry repository for your AWS account : aws ecr create-repository --cli-input-json file://EDP-Repo.json --repository-name ${EDP_NAME} Next, lets create an Amazon EKS Cluster using the below commands. Using envsubst utility we will be replacing the variables in the Yaml Config file and the eksctl CLI tool will deploy the cluster using the EDP-Cluster-Config.yaml file: envsubst < EDP-Cluster-Config.yaml | eksctl create cluster -f - Next, Build a large docker image size of approximately 1 GB to test this solution by running shell script EDP-Build-Docker-Image.sh: ./EDP-Build-Docker-Image.sh we will create prefetching-data-automation-role with trust policy EDP-Events-Trust-Policy.json which will be assumed by Amazon EventBridge service: aws iam create-role --role-name $EDP_NAME-role --assume-role-policy-document file://EDP-Events-Trust-Policy.json we will run the below command to replace variables in EDP-Events-Policy.json policy file by using envsubst utility and attach the policy to the above created `prefetching-data-automation-role : aws iam put-role-policy --role-name ${EDP_NAME}-role --policy-name ${EDP_NAME}-policy --policy-document \"$(envsubst < EDP-Events-Policy.json)\" Next, lets create Amazon EventBridge Rule to trigger SSM Run Command on successful ECR Image push, using envsubst we will be replacing the variables in the EDP-Events-Rule.json: envsubst < EDP-Events-Rule.json > EDP-Events-Rule-updated.json && aws events put-rule --cli-input-json file://EDP-Events-Rule-updated.json && rm EDP-Events-Rule-updated.json Next, lets Attach the Target as AWS Systems Manager Run Command to AWS EventBridge Rule created above, using envsubst we will be replacing the variables in the EDP-Events-Target.json : envsubst '$EDP_AWS_REGION $EDP_AWS_ACCOUNT $EDP_NAME' < EDP-Events-Target.json > EDP-Events-Target-updated.json && aws events put-targets --rule $EDP_NAME --cli-input-json file://EDP-Events-Target-updated.json && rm EDP-Events-Target-updated.json Next, lets create AWS Systems Manager State Manager Association for new worker nodes to prefetch container images, using envsubst we will be replacing the variables in the EDP-StateManager-Association.json: envsubst '$EDP_AWS_REGION $EDP_AWS_ACCOUNT $EDP_NAME' < EDP-StateManager-Association.json > EDP-StateManager-Association-updated.json && aws ssm create-association --cli-input-json file://EDP-StateManager-Association-updated.json && rm EDP-StateManager-Association-updated.json Note: Status might show failed for the AWS SSM State Manager association as there is no image present in ECR yet. Validation Now the setup is complete, let\u2019s run some validations on the setup for Event Driven process to prefetch data to EKS Nodes, First test is to verify if the container images are getting fetched to existing worker nodes automatically upon a container image push. Lets run the following command to get authenticated with ECR repository and push the created container image to Amazon ECR : aws ecr get-login-password --region $EDP_AWS_REGION | docker login --username AWS --password-stdin $EDP_AWS_ACCOUNT.dkr.ecr.$EDP_AWS_REGION.amazonaws.com docker push $EDP_AWS_ACCOUNT.dkr.ecr.$EDP_AWS_REGION.amazonaws.com/$EDP_NAME Now lets check if the event rule we created on the Amazon EventBridge has been triggered. In your Amazon EventBridge console, Navigate to TriggeredRules under Monitoring tab. If there are no FailedInvocations datapoints, then EventBridge has delivered the event to the target successfully which in this case is AWS Systems Manager Run Command (Note: It might take 3 to 5 mins for the data points to be published in the Monitoring graphs) [Image: Image.jpg]Next lets verify if AWS Systems Manager Run Command is triggered by Amazon EventBridge. Run the below command to see the invocations. Look for DocumentName which should be AWS-RunShellScript, RequestedDateTime to identify corresponding run, and then status to make sure if the Run Command executed Successfully or not. aws ssm list-command-invocations --details --filter \"[{\\\"key\\\": \\\"DocumentName\\\", \\\"value\\\": \\\"arn:aws:ssm:us-east-1::document/AWS-RunShellScript\\\"}]\" Output: { \"CommandInvocations\": [ { \"CommandId\": \"eeb9d869-421d-488f-b1ba-ce93a69db2b0\", \"InstanceId\": \"i-0e1a4977c389 * \", \"InstanceName\": \"ip-192-168-29-214.ec2.internal\", \"Comment\": \"\", \"DocumentName\": \"arn:aws:ssm:us-east-1::document/AWS-RunShellScript\", \"DocumentVersion\": \"$DEFAULT\", \"RequestedDateTime\": \"2023-02-17T17:35:48.520000-06:00\", \"Status\": \"Success\", \"StatusDetails\": \"Success\", ....... ....... Next, lets verify if the Image has been copied in to worker node of your Amazon EKS Cluster using the below command: aws ec2 describe-instances \\ --filters \"Name=tag:eks:cluster-name,Values=$EDP_NAME\" \"Name=tag:eks:nodegroup-name,Values=nodegroup\" \\ --query \"Reservations[ ].Instances[ ].InstanceId\" \\ --output text | xargs -I {} aws ssm start-session \\ --target {} \\ --document-name AWS-StartInteractiveCommand \\ --parameters \"command=echo \\$(curl -s http://169.254.169.254/latest/meta-data/instance-id) && sudo docker images\" \\ --region $EDP_AWS_REGION Output: Starting session with SessionId: nbbat-0cf87cdf534 * ........ REPOSITORY TAG IMAGE ID CREATED SIZE 0266528 ***.dkr.ecr.us-east-1.amazonaws.com/prefetching-data-automation latest d50f7ccece64 50 minutes ago 1.23GB ....... Second Test is to validate the container image getting copied to new worker node for any newly added Amazon EKS worker node Lets create new worker node as part of EKS Cluster using below command : eksctl scale nodegroup --cluster $EDP_NAME --name nodegroup --nodes 2 --nodes-min 1 --nodes-max 3 Next, lets verify if the AWS System Manager State Manager Association has been triggered and association execution is successful. Note: Please wait for for few minutes for new worker node to come up and run below command aws ssm list-associations \\ --association-filter-list \"key=AssociationName,value=$EDP_NAME\" Output: { \"Associations\": [ { \"Name\": \"AWS-RunShellScript\", \"AssociationId\": \"d9c82d84-0ceb-4f0f-a8d8-35cd67d1a66e\", ...... \"AssociationStatusAggregatedCount\": { \"Failed\": 1, \"Success\": 1 } }, \"AssociationName\": \"prefetching-data-automation\" } ] } Next, lets verify if the Image has been copied in to worker node of your Amazon EKS Cluster using the below command: aws ec2 describe-instances \\ --filters \"Name=tag:eks:cluster-name,Values=$EDP_NAME\" \"Name=tag:eks:nodegroup-name,Values=nodegroup\" \\ --query \"Reservations[ ].Instances[ ].InstanceId\" \\ --output text | xargs -I {} aws ssm start-session \\ --target {} \\ --document-name AWS-StartInteractiveCommand \\ --parameters \"command=echo \\$(curl -s http://169.254.169.254/latest/meta-data/instance-id) && sudo docker images\" \\ --region $EDP_AWS_REGION Output: Starting session with SessionId: nbbat-0cf87cdf5347 * ........ REPOSITORY TAG IMAGE ID CREATED SIZE 0266528 ***.dkr.ecr.us-east-1.amazonaws.com/prefetching-data-automation latest d50f7ccece64 50 minutes ago 1.23GB ....... Final Test is identify the time difference for a Kubernetes pod to get to running with a Container Image pulled from Amazon ECR vs Image pulled locally Final Test A Delete the locally cached/copied image from one of the worker nodes using the following commands Grab the instance ID \u00b6 InstanceID=$(kubectl get nodes -o jsonpath='{.items[*].spec.providerID}' | awk -F/ '{print $NF}') SSH to the instance \u00b6 aws ssm start-session \\ --target $InstanceID \\ --region $EDP_AWS_REGION List the locally cached image that you pushed in one of the above step \u00b6 sudo su docker images Delete the locally cached images \u00b6 docker rmi Exit out of the SSM session Next, lets pull the latest container image and create a Kubernetes Pod : sh EDP_Pod.sh kubectl apply -f EDP-Pod.yaml Now lets run below command to check how long it took for pod to get in to running state kubectl describe pod $EDP_NAME Output: nbbathul@88665a1f8bb5 EDP_Working % kubectl describe pod prefetching-data-automation Name: prefetching-data-automation Namespace: default Priority: 0 Node: ip-192-168-19-136.ec2.internal/192.168.19.136 Start Time: Thu, 09 Mar 2023 23:03:52 -0600 Labels: Annotations: kubernetes.io/psp: eks.privileged Status: Running IP: 192.168.23.89 IPs: IP: 192.168.23.89 Containers: prefetching-data-automation: Container ID: containerd://29579b61aaca8597bade857458e95b669ab7fca142c1e8f733cfec07d15d9d4d Image: 022435809194.dkr.ecr.us-east-1.amazonaws.com/prefetching-data-automation:latest Image ID: 022435809194.dkr.ecr.us-east-1.amazonaws.com/prefetching-data-automation@sha256:d7a93473bd682ed53acbaba18405532e6c1026c35b7d04ffc96ad89d2221736c Port: Host Port: Command: sleep 3600 State: Running Started: Thu, 09 Mar 2023 23:04:52 -0600 Ready: True Restart Count: 0 Environment: Next, lets also validate time take by pod to get in to running state by running below commands chmod +x EDP-Get-Pod-Boot-Time.sh for pod in $(kubectl get --no-headers=true pods -o name | awk -F \"/\" '{print $2}'); do ./EDP-Get-Pod-Boot-Time.sh $pod ; done >> EDP-Pod-Up-Time-With-Image-From-ECR.txt cat EDP-Pod-Up-Time-With-Image-From-ECR.txt Output : It took 60 seconds for test to boot up Final Test B Next, delete the Kubernetes Pod, create another pod by using sample pod definition file created in above and calculated the time it took to get to running state, since the image is cached locally this time it shouldn\u2019t take long to start the pod : kubectl delete pod $EDP_NAME kubectl apply -f EDP-Pod.yaml Now lets run below command to check how long it took for pod to get in to running state kubectl describe pod $EDP_NAME Output: nbbathul@88665a1f8bb5 EDP_Working % kubectl describe pod prefetching-data-automation Name: prefetching-data-automation Namespace: default Priority: 0 Node: ip-192-168-19-136.ec2.internal/192.168.19.136 Start Time: Thu, 09 Mar 2023 23:20:05 -0600 Labels: Annotations: kubernetes.io/psp: eks.privileged Status: Running IP: 192.168.10.39 IPs: IP: 192.168.10.39 Containers: prefetching-data-automation: Container ID: containerd://fc06a2c5f5ee7734b2a9c4fd893acd1aca7c314ba035b6a01fa9954ae48a69fb Image: 022435809194.dkr.ecr.us-east-1.amazonaws.com/prefetching-data-automation:latest Image ID: 022435809194.dkr.ecr.us-east-1.amazonaws.com/prefetching-data-automation@sha256:d7a93473bd682ed53acbaba18405532e6c1026c35b7d04ffc96ad89d2221736c Port: Host Port: Command: sleep 3600 State: Running Started: Thu, 09 Mar 2023 23:20:06 -0600 Ready: True Restart Count: 0 Environment: Next, lets also validate time take by pod to get in to running state by running below commands for pod in $(kubectl get --no-headers=true pods -o name | awk -F \"/\" '{print $2}'); do ./EDP-Get-Pod-Boot-Time.sh $pod ; done >> EDP-Pod-Up-Time-With-Image-From-Workernode.txt cat EDP-Pod-Up-Time-With-Image-From-Workernode.txt Output: It took 1 second for test to boot up Below table shows time it took for Pod that has been created with locally cached image is drastically less when compared to Pod that has been created with image that got pulled from ECR repository. Final Test A Final Test B Pod Start Time 23:03:52 -0600 23:20:05 -0600 Pod Running Time 23:04:52 -0600 23:20:06 -0600 Total Time Taken 60 Seconds 1 Second Final Test A: Created Pod by pulling image from ECR repo Final Test B: Created Pod by pulling locally cached Image Cleanup chmod +x EDP-Cleanup.sh ./EDP-Cleanup.sh","title":"Prefetch Images to EKS nodes"},{"location":"prefetch-data-to-eks-nodes/#grab-the-instance-id","text":"InstanceID=$(kubectl get nodes -o jsonpath='{.items[*].spec.providerID}' | awk -F/ '{print $NF}')","title":"Grab the instance ID"},{"location":"prefetch-data-to-eks-nodes/#ssh-to-the-instance","text":"aws ssm start-session \\ --target $InstanceID \\ --region $EDP_AWS_REGION","title":"SSH to the instance"},{"location":"prefetch-data-to-eks-nodes/#list-the-locally-cached-image-that-you-pushed-in-one-of-the-above-step","text":"sudo su docker images","title":"List the locally cached image that you pushed in one of the above step"},{"location":"prefetch-data-to-eks-nodes/#delete-the-locally-cached-images","text":"docker rmi Exit out of the SSM session Next, lets pull the latest container image and create a Kubernetes Pod : sh EDP_Pod.sh kubectl apply -f EDP-Pod.yaml Now lets run below command to check how long it took for pod to get in to running state kubectl describe pod $EDP_NAME Output: nbbathul@88665a1f8bb5 EDP_Working % kubectl describe pod prefetching-data-automation Name: prefetching-data-automation Namespace: default Priority: 0 Node: ip-192-168-19-136.ec2.internal/192.168.19.136 Start Time: Thu, 09 Mar 2023 23:03:52 -0600 Labels: Annotations: kubernetes.io/psp: eks.privileged Status: Running IP: 192.168.23.89 IPs: IP: 192.168.23.89 Containers: prefetching-data-automation: Container ID: containerd://29579b61aaca8597bade857458e95b669ab7fca142c1e8f733cfec07d15d9d4d Image: 022435809194.dkr.ecr.us-east-1.amazonaws.com/prefetching-data-automation:latest Image ID: 022435809194.dkr.ecr.us-east-1.amazonaws.com/prefetching-data-automation@sha256:d7a93473bd682ed53acbaba18405532e6c1026c35b7d04ffc96ad89d2221736c Port: Host Port: Command: sleep 3600 State: Running Started: Thu, 09 Mar 2023 23:04:52 -0600 Ready: True Restart Count: 0 Environment: Next, lets also validate time take by pod to get in to running state by running below commands chmod +x EDP-Get-Pod-Boot-Time.sh for pod in $(kubectl get --no-headers=true pods -o name | awk -F \"/\" '{print $2}'); do ./EDP-Get-Pod-Boot-Time.sh $pod ; done >> EDP-Pod-Up-Time-With-Image-From-ECR.txt cat EDP-Pod-Up-Time-With-Image-From-ECR.txt Output : It took 60 seconds for test to boot up Final Test B Next, delete the Kubernetes Pod, create another pod by using sample pod definition file created in above and calculated the time it took to get to running state, since the image is cached locally this time it shouldn\u2019t take long to start the pod : kubectl delete pod $EDP_NAME kubectl apply -f EDP-Pod.yaml Now lets run below command to check how long it took for pod to get in to running state kubectl describe pod $EDP_NAME Output: nbbathul@88665a1f8bb5 EDP_Working % kubectl describe pod prefetching-data-automation Name: prefetching-data-automation Namespace: default Priority: 0 Node: ip-192-168-19-136.ec2.internal/192.168.19.136 Start Time: Thu, 09 Mar 2023 23:20:05 -0600 Labels: Annotations: kubernetes.io/psp: eks.privileged Status: Running IP: 192.168.10.39 IPs: IP: 192.168.10.39 Containers: prefetching-data-automation: Container ID: containerd://fc06a2c5f5ee7734b2a9c4fd893acd1aca7c314ba035b6a01fa9954ae48a69fb Image: 022435809194.dkr.ecr.us-east-1.amazonaws.com/prefetching-data-automation:latest Image ID: 022435809194.dkr.ecr.us-east-1.amazonaws.com/prefetching-data-automation@sha256:d7a93473bd682ed53acbaba18405532e6c1026c35b7d04ffc96ad89d2221736c Port: Host Port: Command: sleep 3600 State: Running Started: Thu, 09 Mar 2023 23:20:06 -0600 Ready: True Restart Count: 0 Environment: Next, lets also validate time take by pod to get in to running state by running below commands for pod in $(kubectl get --no-headers=true pods -o name | awk -F \"/\" '{print $2}'); do ./EDP-Get-Pod-Boot-Time.sh $pod ; done >> EDP-Pod-Up-Time-With-Image-From-Workernode.txt cat EDP-Pod-Up-Time-With-Image-From-Workernode.txt Output: It took 1 second for test to boot up Below table shows time it took for Pod that has been created with locally cached image is drastically less when compared to Pod that has been created with image that got pulled from ECR repository. Final Test A Final Test B Pod Start Time 23:03:52 -0600 23:20:05 -0600 Pod Running Time 23:04:52 -0600 23:20:06 -0600 Total Time Taken 60 Seconds 1 Second Final Test A: Created Pod by pulling image from ECR repo Final Test B: Created Pod by pulling locally cached Image Cleanup chmod +x EDP-Cleanup.sh ./EDP-Cleanup.sh","title":"Delete the locally cached images"},{"location":"semantic-versioning-app-runner/","text":"Enable continuous deployment based on semantic versioning using AWS App Runner \u00b6 Introduction \u00b6 In this modern cloud era, customers automatically build, test, and deploy the new version of their application multiple times a day, and this is a common scenario in the software development life cycle as it allows for faster delivery of features, bug fixes, and other updates to end users. One key aspect of continuous deployment is semantic versioning, a system for assigning version numbers to software releases. Semantic versioning uses a standard format to convey the level of change in a release, allowing developers and users to understand the potential impact of an update. In this blog post, we will show you how to use semantic versioning combined with the CI/CD capabilities App Runner provides to deploy new versions of the application automatically. Semantic Versioning \u00b6 Semantic versioning is a system for assigning version numbers to software releases. It uses a standard format to convey the level of change in a release, allowing developers and users to understand the potential impact of an update. The basic format of a semantic version number is MAJOR.MINOR.PATCH , where each component is a non-negative integer. Here are some general rules for semantic versioning: * When a release contains backward-incompatible changes, the MAJOR version is incremented. * When a release contains backward-compatible changes, the MINOR version is incremented. * PATCH version is incremented for releases that contain only bug fixes and no other changes. By using semantic versioning, developers can communicate the impact of a release to users, making it easier to understand the risks and benefits of updating to a new version. It also helps organizations to adopt a more predictable and consistent approach to versioning and releasing their software. Semantic versioning is not a replacement for a changelog or release notes. It is a way to convey the impact of a release, but it does not provide any information about the changes made. Problem Statement \u00b6 AWS App Runner is a fully managed container application service that makes it easy to deploy containerized applications from source code repositories quickly. App Runner provides a fully controlled environment to build, run, and scale containerized applications. It also provides a fully managed CI/CD pipeline to build and deploy new application versions automatically. Customers can leverage App Runner to continuously monitor their ECR repository for new images based on a fixed tag (like LATEST ) and automatically deploy the new version of the application to the underlying App Runner service. However, this approach does not allow customers to monitor and deploy the new version of the application based on semantic versioning. Let's say the customer wants App Runner to automatically deploy the new application version based on a match pattern like >= MAJOR1.MINOR2.PATCH3 , this is not possible with the current App Runner capabilities. Customer Benefits \u00b6 Here are some of the benefits of using the solution outlined in this post: Customers can use semantic versioning to communicate the impact of a release to users, making it easier to understand the risks and benefits of updating to a new version. Customers can use App Runner to automatically deploy new versions of the application based on semantic versioning. Customers can use unique tags (based on build ID, git commit) for each version of the application, making tracking and managing the application versions easier. With this approach, customers can start following the best practices in versioning and releasing their software. Yet, they can still leverage App Runner to roll out these changes to their end users without worrying about the underlying infrastructure. The solution outlined in this post is scalable and can deploy multiple applications without additional cost. Solution Overview \u00b6 In this solution we use the following AWS services: * AWS App Runner - Fully managed container application service that makes it easy to quickly deploy containerized applications from source code repositories. * AWS Lambda - Serverless compute service that allows you to run code without provisioning or managing servers. * AWS ECR - Fully managed Docker container registry that makes it easy for developers to store, manage, and deploy Docker container images. * AWS EventBridge - Fully managed event bus that makes it easy to connect applications together using data from your own applications, Software-as-a-Service (SaaS) applications, and AWS services. * AWS S3 - Fully managed object storage service that offers industry-leading scalability, data availability, security, and performance. The following diagram shows the overall architecture of the solution: The solution uses Event bridge rules to listen to the ECR PUSH events, which get processed by a Lambda function via an SQS queue. The lambda function uses AWS App Runner APIs to fetch the currently deployed version of the application and compare it with the imageTag that got pushed to the ECR repository. If there is a match (based on semantic versioning), the Lambda function updates the App Runner service to deploy the new version of the application. Customers can provide the match pattern as an input parameter to the Lambda function in the form of a JSON file (sample below) stored in an S3 bucket. [ { \"repository\" : \"Hello-World-AppRunner-Repo\" , \"semVersion\" : \">1.2.3\" , \"serviceArn\" : \"arn:aws:apprunner:us-east-1:123456789123:service/Hello-World-Service/2d0032a93cbb4cbdaef0966607052336\" } ] The solution supports NPM style versioning checks, and here are some examples of the match patterns that are supported: * >1.2.3 - Matches any version greater than 1.2.3. * 1.1.1 || 1.2.3 - 2.0.0 - Matches 1.1.1 version or any version between 1.2.3 & 2.0.0 (including). * 1.1.* - Matches any version starting with 1.1. * ~1.2.1 - Matches any version greater than or equal to 1.2.1 but less than 1.3.0. * ^1.2.1 - Matches any version greater than or equal to 1.2.1 but less than 2.0.0. The following environment variables need to be set in the Lambda function: * QUEUE_NAME - Name of the SQS queue that will receive the ECR push events and trigger the lambda function. * CONFIG_BUCKET - Name of the S3 bucket that contains the JSON file with the match pattern. * CONFIG_FILE - Name of the JSON file that contains the match pattern (sample provided under config folder). The below sequence diagram shows the interaction between different components of the solution, when a new version of the application gets pushed to the ECR repository: Retry Logic: If there are multiple ECR push events on the same repository, the Lambda function will first check whether there is an ongoing deployment for the target App Runner service. If a deployment is in progress, the Lambda function will wait for the deployment to complete and retry again after 10 minutes. Lambda will retry a maximum of 3 times before giving up. Pre-requisites \u00b6 To implement this solution, you need the following prerequisites: The AWS Command Line Interface (AWS CLI) installed . The AWS CLI is a unified tool to manage your AWS services. The AWS CDK installed on your local laptop. Git installed and configured on your machine. jq installed on your machine. Deployment \u00b6 Setup ECR repository and App Runner Service \u00b6 Note: Let us demonstrate the solution by using the hello world sample application from the App Runner documentation. Checkout the sample application from Github. mkdir hello-app-runner && cd hello-app-runner git clone https://github.com/aws-containers/hello-app-runner.git . Create a new ECR repository. aws ecr create-repository --repository-name hello-world-apprunner-repo Output { \"repository\" : { \"repositoryArn\" : \"arn:aws:ecr:us-east-1:<<account>>:repository/hello-world-apprunner-repo\" , \"registryId\" : \"<<account>>\" , \"repositoryName\" : \"hello-world-apprunner-repo\" , \"repositoryUri\" : \"<<account>>.dkr.ecr.us-east-1.amazonaws.com/hello-world-apprunner-repo\" , \"createdAt\" : \"2023-01-02T15:20:14-08:00\" , \"imageTagMutability\" : \"MUTABLE\" , \"imageScanningConfiguration\" : { \"scanOnPush\" : false }, \"encryptionConfiguration\" : { \"encryptionType\" : \"AES256\" } } } Login to the ECR repository. aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <<account>>.dkr.ecr.us-ea st-1.amazonaws.com Build the docker image, tag and push it to the ECR repository. docker build -t hello-world-apprunner-repo . docker tag hello-world-apprunner-repo:latest <<account>>.dkr.ecr.us-east-1.amazonaws.com/hello-world-apprunner-repo:1.2.3 docker push <<account >>.dkr.ecr.us-east-1.amazonaws.com/hello-world-apprunner-repo:1.2.3 Create a App Runner access role and attach ECR access policy to it. export TP_FILE = $( mktemp ) export ROLE_NAME = AppRunnerSemVarAccessRole cat <<EOF | tee $TP_FILE { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"build.apprunner.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\" } ] } EOF aws iam create-role --role-name $ROLE_NAME --assume-role-policy-document file:// $TP_FILE rm $TP_FILE aws iam attach-role-policy --role-name $ROLE_NAME --policy-arn arn:aws:iam::aws:policy/service-role/AWSAppRunnerServicePolicyForECRAccess Create a new App Runner service using the ECR repository that was created in the previous step. aws apprunner create-service --cli-input-json file://input.json Contents of input.json : { \"ServiceName\" : \"hello-world-service\" , \"SourceConfiguration\" : { \"AuthenticationConfiguration\" : { \"AccessRoleArn\" : \"arn:aws:iam::${AWS_REGION}:role/${ROLE_NAME}\" }, \"ImageRepository\" : { \"ImageIdentifier\" : \"${AWS_ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com/hello-world-apprunner-repo:1.2.3\" , \"ImageConfiguration\" : { \"Port\" : \"8000\" }, \"ImageRepositoryType\" : \"ECR\" } }, \"InstanceConfiguration\" : { \"CPU\" : \"1 vCPU\" , \"Memory\" : \"3 GB\" } } Output Keep track of the ServiceArn (sample below) returned in the output. This will be used in the next step. arn:aws:apprunner:us-east-1:<<accountId>:service/hello-world-service/<<serviceId>> Once the service is created, you can access the application using the URL that is displayed in the App Runner console. You should see the following output: Deploy the solution \u00b6 Checkout the solution from github mkdir sem-var-ecr-watcher-app-runner && cd sem-var-ecr-watcher-app-runner git clone https://github.com/hariohmprasath/sem-var-ecr-watcher-app-runner.git . Update the serviceARN attribute inside config.json file under config/ folder with the ServiceArn that was returned in the previous step (sample below). { \"serviceARN\" : \"arn:aws:apprunner:us-east-1:<<accountId>:service/hello-world-service/<<serviceId>>\" , } If you\u2019re running AWS CDK for the first time, run the following command to bootstrap the AWS CDK environment (provide your AWS account ID and AWS Region): cdk bootstrap \\ --cloudformation-execution-policies arn:aws:iam::aws:policy/AdministratorAccess \\ aws://<AWS Account Id>/<AWS_REGION> Note: You only need to bootstrap the AWS CDK one time (skip this step if you have already done this). Run the following command to deploy the code: cdk deploy --requires-approval Testing \u00b6 You must publish a new application version to the ECR repository to test the solution. The latest version should match the semver pattern ( >1.2.3 ) that is specified in the config.json file inside the S3 bucket. Update hello world application, by opening templates\\index.html and changing And we're live, one more time! to And we're live, one more time! v1.2.4 in line #183 Build the docker image, tag and push it to the ECR repository. docker build -t hello-world-apprunner-repo . docker tag hello-world-apprunner-repo:latest <<account>>.dkr.ecr.us-east-1.amazonaws.com/hello-world-apprunner-repo:1.2.4 docker push <<account >>.dkr.ecr.us-east-1.amazonaws.com/hello-world-apprunner-repo:1.2.4 The above action will trigger an ECR event, which will get picked up by the Lambda function. The Lambda function will update the App Runner service with the new image in a few seconds. You can verify this by running the following command: aws apprunner describe-service --service-arn arn:aws:apprunner:us-east-1: <<accountId>:service/hello-world-service/<<serviceId>> | jq -r '.Service.Sta tus ' Output OPERATION_IN_PROGRESS Event logs for the App Runner service will show the following, to confirm the update is being triggered by the deployed solution: 12 -30-2022 01 :55:48 PM [ CI/CD ] Semantic version >1.2.2 matched with the recent ECR push 1 .2.4, so updating the service to the deploy from the latest version When the update is successful, you will see the following output with the changes applied to the App Runner service: Clean Up \u00b6 Run the following command from the root directory to delete the stack: cdk destroy aws ecr delete-repository --repository-name hello-world-apprunner-repo --force aws iam delete-role --role-name ${ ROLE_NAME } Considerations \u00b6 Here are some essential items to consider before using this solution: The solution uses AWS App Runner APIs to update and deploy the new version of the application, so it is not a fully managed solution. The customer needs to manage the AWS CDK stack and the Lambda function. The solution does not support tracking latest tag. If the customer wants to track the latest or fixed tag, we recommend using the native CI/CD support in App Runner. The solution uses various AWS services (like Eventbridge, SQS, Lambda) to track the semantic version pattern. As the solution relays on Eventbridge events, SQS messages and Lambda invocations to track the semantic version, it can get expensive if the customer tracks multiple App Runner services and ECR repositories as it would result in multiple events, SQS messages and invocations. It can get expensive if the customer tracks multiple App Runner services and ECR repositories. The code is not production ready and is provided as is. The customer should test the solution in a non-production environment before using it. The solution does not support tracking multiple App Runner services using the same repository. If the customer wants to use the same repository for multiple App Runner services based on the semantic version, then the solution code needs to get updated to support this use case. Conclusion \u00b6 This post showed how customers could power their release pipelines based on semantic versioning and deliver new versions of the application to their customers fully automatedly using App Runner. If you have any questions or feedback, please leave a comment below. References \u00b6 AWS App Runner Semantic Versioning AWS CDK Build a Continuous Delivery Pipeline for Your Container Images with Amazon ECR as Source","title":"Semantic Versioning App Runner"},{"location":"semantic-versioning-app-runner/#enable-continuous-deployment-based-on-semantic-versioning-using-aws-app-runner","text":"","title":"Enable continuous deployment based on semantic versioning using AWS App Runner"},{"location":"semantic-versioning-app-runner/#introduction","text":"In this modern cloud era, customers automatically build, test, and deploy the new version of their application multiple times a day, and this is a common scenario in the software development life cycle as it allows for faster delivery of features, bug fixes, and other updates to end users. One key aspect of continuous deployment is semantic versioning, a system for assigning version numbers to software releases. Semantic versioning uses a standard format to convey the level of change in a release, allowing developers and users to understand the potential impact of an update. In this blog post, we will show you how to use semantic versioning combined with the CI/CD capabilities App Runner provides to deploy new versions of the application automatically.","title":"Introduction"},{"location":"semantic-versioning-app-runner/#semantic-versioning","text":"Semantic versioning is a system for assigning version numbers to software releases. It uses a standard format to convey the level of change in a release, allowing developers and users to understand the potential impact of an update. The basic format of a semantic version number is MAJOR.MINOR.PATCH , where each component is a non-negative integer. Here are some general rules for semantic versioning: * When a release contains backward-incompatible changes, the MAJOR version is incremented. * When a release contains backward-compatible changes, the MINOR version is incremented. * PATCH version is incremented for releases that contain only bug fixes and no other changes. By using semantic versioning, developers can communicate the impact of a release to users, making it easier to understand the risks and benefits of updating to a new version. It also helps organizations to adopt a more predictable and consistent approach to versioning and releasing their software. Semantic versioning is not a replacement for a changelog or release notes. It is a way to convey the impact of a release, but it does not provide any information about the changes made.","title":"Semantic Versioning"},{"location":"semantic-versioning-app-runner/#problem-statement","text":"AWS App Runner is a fully managed container application service that makes it easy to deploy containerized applications from source code repositories quickly. App Runner provides a fully controlled environment to build, run, and scale containerized applications. It also provides a fully managed CI/CD pipeline to build and deploy new application versions automatically. Customers can leverage App Runner to continuously monitor their ECR repository for new images based on a fixed tag (like LATEST ) and automatically deploy the new version of the application to the underlying App Runner service. However, this approach does not allow customers to monitor and deploy the new version of the application based on semantic versioning. Let's say the customer wants App Runner to automatically deploy the new application version based on a match pattern like >= MAJOR1.MINOR2.PATCH3 , this is not possible with the current App Runner capabilities.","title":"Problem Statement"},{"location":"semantic-versioning-app-runner/#customer-benefits","text":"Here are some of the benefits of using the solution outlined in this post: Customers can use semantic versioning to communicate the impact of a release to users, making it easier to understand the risks and benefits of updating to a new version. Customers can use App Runner to automatically deploy new versions of the application based on semantic versioning. Customers can use unique tags (based on build ID, git commit) for each version of the application, making tracking and managing the application versions easier. With this approach, customers can start following the best practices in versioning and releasing their software. Yet, they can still leverage App Runner to roll out these changes to their end users without worrying about the underlying infrastructure. The solution outlined in this post is scalable and can deploy multiple applications without additional cost.","title":"Customer Benefits"},{"location":"semantic-versioning-app-runner/#solution-overview","text":"In this solution we use the following AWS services: * AWS App Runner - Fully managed container application service that makes it easy to quickly deploy containerized applications from source code repositories. * AWS Lambda - Serverless compute service that allows you to run code without provisioning or managing servers. * AWS ECR - Fully managed Docker container registry that makes it easy for developers to store, manage, and deploy Docker container images. * AWS EventBridge - Fully managed event bus that makes it easy to connect applications together using data from your own applications, Software-as-a-Service (SaaS) applications, and AWS services. * AWS S3 - Fully managed object storage service that offers industry-leading scalability, data availability, security, and performance. The following diagram shows the overall architecture of the solution: The solution uses Event bridge rules to listen to the ECR PUSH events, which get processed by a Lambda function via an SQS queue. The lambda function uses AWS App Runner APIs to fetch the currently deployed version of the application and compare it with the imageTag that got pushed to the ECR repository. If there is a match (based on semantic versioning), the Lambda function updates the App Runner service to deploy the new version of the application. Customers can provide the match pattern as an input parameter to the Lambda function in the form of a JSON file (sample below) stored in an S3 bucket. [ { \"repository\" : \"Hello-World-AppRunner-Repo\" , \"semVersion\" : \">1.2.3\" , \"serviceArn\" : \"arn:aws:apprunner:us-east-1:123456789123:service/Hello-World-Service/2d0032a93cbb4cbdaef0966607052336\" } ] The solution supports NPM style versioning checks, and here are some examples of the match patterns that are supported: * >1.2.3 - Matches any version greater than 1.2.3. * 1.1.1 || 1.2.3 - 2.0.0 - Matches 1.1.1 version or any version between 1.2.3 & 2.0.0 (including). * 1.1.* - Matches any version starting with 1.1. * ~1.2.1 - Matches any version greater than or equal to 1.2.1 but less than 1.3.0. * ^1.2.1 - Matches any version greater than or equal to 1.2.1 but less than 2.0.0. The following environment variables need to be set in the Lambda function: * QUEUE_NAME - Name of the SQS queue that will receive the ECR push events and trigger the lambda function. * CONFIG_BUCKET - Name of the S3 bucket that contains the JSON file with the match pattern. * CONFIG_FILE - Name of the JSON file that contains the match pattern (sample provided under config folder). The below sequence diagram shows the interaction between different components of the solution, when a new version of the application gets pushed to the ECR repository: Retry Logic: If there are multiple ECR push events on the same repository, the Lambda function will first check whether there is an ongoing deployment for the target App Runner service. If a deployment is in progress, the Lambda function will wait for the deployment to complete and retry again after 10 minutes. Lambda will retry a maximum of 3 times before giving up.","title":"Solution Overview"},{"location":"semantic-versioning-app-runner/#pre-requisites","text":"To implement this solution, you need the following prerequisites: The AWS Command Line Interface (AWS CLI) installed . The AWS CLI is a unified tool to manage your AWS services. The AWS CDK installed on your local laptop. Git installed and configured on your machine. jq installed on your machine.","title":"Pre-requisites"},{"location":"semantic-versioning-app-runner/#deployment","text":"","title":"Deployment"},{"location":"semantic-versioning-app-runner/#setup-ecr-repository-and-app-runner-service","text":"Note: Let us demonstrate the solution by using the hello world sample application from the App Runner documentation. Checkout the sample application from Github. mkdir hello-app-runner && cd hello-app-runner git clone https://github.com/aws-containers/hello-app-runner.git . Create a new ECR repository. aws ecr create-repository --repository-name hello-world-apprunner-repo Output { \"repository\" : { \"repositoryArn\" : \"arn:aws:ecr:us-east-1:<<account>>:repository/hello-world-apprunner-repo\" , \"registryId\" : \"<<account>>\" , \"repositoryName\" : \"hello-world-apprunner-repo\" , \"repositoryUri\" : \"<<account>>.dkr.ecr.us-east-1.amazonaws.com/hello-world-apprunner-repo\" , \"createdAt\" : \"2023-01-02T15:20:14-08:00\" , \"imageTagMutability\" : \"MUTABLE\" , \"imageScanningConfiguration\" : { \"scanOnPush\" : false }, \"encryptionConfiguration\" : { \"encryptionType\" : \"AES256\" } } } Login to the ECR repository. aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <<account>>.dkr.ecr.us-ea st-1.amazonaws.com Build the docker image, tag and push it to the ECR repository. docker build -t hello-world-apprunner-repo . docker tag hello-world-apprunner-repo:latest <<account>>.dkr.ecr.us-east-1.amazonaws.com/hello-world-apprunner-repo:1.2.3 docker push <<account >>.dkr.ecr.us-east-1.amazonaws.com/hello-world-apprunner-repo:1.2.3 Create a App Runner access role and attach ECR access policy to it. export TP_FILE = $( mktemp ) export ROLE_NAME = AppRunnerSemVarAccessRole cat <<EOF | tee $TP_FILE { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"build.apprunner.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\" } ] } EOF aws iam create-role --role-name $ROLE_NAME --assume-role-policy-document file:// $TP_FILE rm $TP_FILE aws iam attach-role-policy --role-name $ROLE_NAME --policy-arn arn:aws:iam::aws:policy/service-role/AWSAppRunnerServicePolicyForECRAccess Create a new App Runner service using the ECR repository that was created in the previous step. aws apprunner create-service --cli-input-json file://input.json Contents of input.json : { \"ServiceName\" : \"hello-world-service\" , \"SourceConfiguration\" : { \"AuthenticationConfiguration\" : { \"AccessRoleArn\" : \"arn:aws:iam::${AWS_REGION}:role/${ROLE_NAME}\" }, \"ImageRepository\" : { \"ImageIdentifier\" : \"${AWS_ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com/hello-world-apprunner-repo:1.2.3\" , \"ImageConfiguration\" : { \"Port\" : \"8000\" }, \"ImageRepositoryType\" : \"ECR\" } }, \"InstanceConfiguration\" : { \"CPU\" : \"1 vCPU\" , \"Memory\" : \"3 GB\" } } Output Keep track of the ServiceArn (sample below) returned in the output. This will be used in the next step. arn:aws:apprunner:us-east-1:<<accountId>:service/hello-world-service/<<serviceId>> Once the service is created, you can access the application using the URL that is displayed in the App Runner console. You should see the following output:","title":"Setup ECR repository and App Runner Service"},{"location":"semantic-versioning-app-runner/#deploy-the-solution","text":"Checkout the solution from github mkdir sem-var-ecr-watcher-app-runner && cd sem-var-ecr-watcher-app-runner git clone https://github.com/hariohmprasath/sem-var-ecr-watcher-app-runner.git . Update the serviceARN attribute inside config.json file under config/ folder with the ServiceArn that was returned in the previous step (sample below). { \"serviceARN\" : \"arn:aws:apprunner:us-east-1:<<accountId>:service/hello-world-service/<<serviceId>>\" , } If you\u2019re running AWS CDK for the first time, run the following command to bootstrap the AWS CDK environment (provide your AWS account ID and AWS Region): cdk bootstrap \\ --cloudformation-execution-policies arn:aws:iam::aws:policy/AdministratorAccess \\ aws://<AWS Account Id>/<AWS_REGION> Note: You only need to bootstrap the AWS CDK one time (skip this step if you have already done this). Run the following command to deploy the code: cdk deploy --requires-approval","title":"Deploy the solution"},{"location":"semantic-versioning-app-runner/#testing","text":"You must publish a new application version to the ECR repository to test the solution. The latest version should match the semver pattern ( >1.2.3 ) that is specified in the config.json file inside the S3 bucket. Update hello world application, by opening templates\\index.html and changing And we're live, one more time! to And we're live, one more time! v1.2.4 in line #183 Build the docker image, tag and push it to the ECR repository. docker build -t hello-world-apprunner-repo . docker tag hello-world-apprunner-repo:latest <<account>>.dkr.ecr.us-east-1.amazonaws.com/hello-world-apprunner-repo:1.2.4 docker push <<account >>.dkr.ecr.us-east-1.amazonaws.com/hello-world-apprunner-repo:1.2.4 The above action will trigger an ECR event, which will get picked up by the Lambda function. The Lambda function will update the App Runner service with the new image in a few seconds. You can verify this by running the following command: aws apprunner describe-service --service-arn arn:aws:apprunner:us-east-1: <<accountId>:service/hello-world-service/<<serviceId>> | jq -r '.Service.Sta tus ' Output OPERATION_IN_PROGRESS Event logs for the App Runner service will show the following, to confirm the update is being triggered by the deployed solution: 12 -30-2022 01 :55:48 PM [ CI/CD ] Semantic version >1.2.2 matched with the recent ECR push 1 .2.4, so updating the service to the deploy from the latest version When the update is successful, you will see the following output with the changes applied to the App Runner service:","title":"Testing"},{"location":"semantic-versioning-app-runner/#clean-up","text":"Run the following command from the root directory to delete the stack: cdk destroy aws ecr delete-repository --repository-name hello-world-apprunner-repo --force aws iam delete-role --role-name ${ ROLE_NAME }","title":"Clean Up"},{"location":"semantic-versioning-app-runner/#considerations","text":"Here are some essential items to consider before using this solution: The solution uses AWS App Runner APIs to update and deploy the new version of the application, so it is not a fully managed solution. The customer needs to manage the AWS CDK stack and the Lambda function. The solution does not support tracking latest tag. If the customer wants to track the latest or fixed tag, we recommend using the native CI/CD support in App Runner. The solution uses various AWS services (like Eventbridge, SQS, Lambda) to track the semantic version pattern. As the solution relays on Eventbridge events, SQS messages and Lambda invocations to track the semantic version, it can get expensive if the customer tracks multiple App Runner services and ECR repositories as it would result in multiple events, SQS messages and invocations. It can get expensive if the customer tracks multiple App Runner services and ECR repositories. The code is not production ready and is provided as is. The customer should test the solution in a non-production environment before using it. The solution does not support tracking multiple App Runner services using the same repository. If the customer wants to use the same repository for multiple App Runner services based on the semantic version, then the solution code needs to get updated to support this use case.","title":"Considerations"},{"location":"semantic-versioning-app-runner/#conclusion","text":"This post showed how customers could power their release pipelines based on semantic versioning and deliver new versions of the application to their customers fully automatedly using App Runner. If you have any questions or feedback, please leave a comment below.","title":"Conclusion"},{"location":"semantic-versioning-app-runner/#references","text":"AWS App Runner Semantic Versioning AWS CDK Build a Continuous Delivery Pipeline for Your Container Images with Amazon ECR as Source","title":"References"}]}